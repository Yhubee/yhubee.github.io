<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Projects and Case Studies by Ubong Eno Nkereuwem - AI + HCI work across EdTech, accessibility, and sociotechnical contexts.">
    <meta name="author" content="Ubong Eno Nkereuwem">
    <title>Projects & Case Studies | Ubong Eno Nkereuwem</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <a href="index.html" class="logo">Ubong Eno Nkereuwem</a>
            <nav>
                <a href="index.html">Home</a>
                <a href="about.html">About</a>
                <a href="projects.html" class="active">Projects</a>
                <a href="research.html">Research</a>
                <a href="teaching.html">Teaching</a>
                <a href="why.html">Why This Work</a>
            </nav>
        </div>
    </header>

    <div class="page-header">
        <div class="container">
            <h1>Projects & Case Studies</h1>
            <p class="lead">A deep dive into my AI + HCI work across EdTech, accessibility, and sociotechnical contexts</p>
        </div>
    </div>

    <main>
        <div class="container">
            <div class="content-wrapper">
                <p>My project work reflects a consistent thread: I use mixed-methods inquiry, sociotechnical reasoning, and ethical design practices to understand how intelligent systems influence, support, and sometimes interfere with human autonomy and decision-making. These case studies represent a blend of research, design, and computational awareness across EdTech, accessibility, and digital services.</p>

                <div class="section-nav" aria-label="Projects page quick links">
                    <h3>On this page</h3>
                    <p>Explore case studies by topic.</p>
                    <ul>
                        <li><a href="#project-1">Human–AI Learning Companion</a></li>
                        <li><a href="#project-2">Fast Track Food Pickup</a></li>
                        <li><a href="#project-3">AI Accessibility for Sky</a></li>
                        <li><a href="#project-4">CSR Data Annotation</a></li>
                        <li><a href="#project-5">Digital Equity &amp; Development</a></li>
                        <li><a href="#project-6">Data, Insight &amp; Behavioral Analysis</a></li>
                        <li><a href="#collaboration">Interested in collaborating?</a></li>
                    </ul>
                </div>

                <hr>

                <!-- Project 1 -->
                <div class="project-card" id="project-1">
                    <h3>1. Human–AI Learning Companion for International Students</h3>
                    <div class="project-meta">
                        <span><strong>Role:</strong> Technical AI Product Manager & Human–Centered AI Researcher</span>
                        <span><strong>Domains:</strong> Decision Support, Explanation Design, Trust Calibration, Digital Learning Ecosystems</span>
                    </div>
                    <p><strong>Methods:</strong> Semi-structured interviews, cognitive mapping, interaction prototyping, behavioral analysis, explainability modeling</p>

                    <div class="project-section">
                        <h4>Overview</h4>
                        <p>International students face complex educational decisions—program selection, visa processes, academic expectations, and career pathways—all while navigating unfamiliar cultural and institutional systems. These decisions involve uncertainty, high stakes, and emotional burden. My work on the AI Learning Companion examined how intelligent guidance systems can support clarity and confidence without inducing over-reliance.</p>
                    </div>

                    <div class="project-section">
                        <h4>Problem Framing</h4>
                        <p>Most digital advising systems present recommendations without transparency. Students experiencing stress or limited familiarity with local academic structures often accept advice unquestioningly. The risk is twofold:</p>
                        <ol>
                            <li>Over-reliance due to cognitive load, perceived authority, or system confidence</li>
                            <li>Erosion of agency when recommendations subtly nudge students toward predefined pathways</li>
                        </ol>
                        <p>My goal was to design an AI system that supports, not supplants, human judgment.</p>
                    </div>

                    <div class="project-section">
                        <h4>What I Did</h4>
                        <p><strong>1. Researching Real Help-Seeking Behaviors</strong></p>
                        <p>I conducted interviews with international students to map:</p>
                        <ul>
                            <li>uncertainty points</li>
                            <li>mental models of institutional processes</li>
                            <li>expectations of AI guidance</li>
                            <li>perceived emotional/life stakes of decisions</li>
                        </ul>
                        <p>Students frequently interpreted AI confidence as correctness, especially when overwhelmed. This echoed patterns I observed in other settings—such as Maria, an autistic user who gradually deferred to an AI system's recommendations because it appeared "sure"—highlighting the universality of confidence bias in AI-mediated decision making.</p>

                        <p><strong>2. Designing Adaptive Explanation Patterns</strong></p>
                        <p>I co-developed an explanation schema that adjusted based on:</p>
                        <ul>
                            <li>question type</li>
                            <li>risk level</li>
                            <li>user uncertainty signals</li>
                            <li>amount of context the user provided</li>
                            <li>whether the user asked for justification or alternatives</li>
                        </ul>
                        <p>Examples included: "reasoned recommendations," "confidence-qualified suggestions," "multiple-pathway explanations," and "limited knowledge disclosures." These aimed to support healthy skepticism and informed choice.</p>

                        <p><strong>3. Introducing Autonomy-Preserving Interaction Boundaries</strong></p>
                        <p>I implemented features such as:</p>
                        <ul>
                            <li>user-managed control settings</li>
                            <li>value-sensitive defaults</li>
                            <li>rationale prompts</li>
                            <li>calls to double-check institutional requirements</li>
                            <li>invitation to reflect ("Does this align with what you want?")</li>
                        </ul>
                        <p>These were grounded in principles of FATE, sensemaking, and human–AI complementarity.</p>
                    </div>

                    <div class="project-section">
                        <h4>Outcomes</h4>
                        <ul>
                            <li>Increased student engagement with learning and advising content</li>
                            <li>Greater user awareness of system limitations</li>
                            <li>Reduced blind acceptance of system recommendations</li>
                            <li>Early evidence of trust calibration (users began questioning recommendations more thoughtfully)</li>
                            <li>Identification of behavioral clusters that now inform adaptive UI/UX flows</li>
                        </ul>
                    </div>

                    <div class="project-section">
                        <h4>Scholarly Contribution</h4>
                        <p>This project helped refine my research agenda on: trust drift over repeated human–AI interactions, explanation strategies tailored to user cognition, longitudinal measurement of autonomy and self-efficacy, and sociotechnical design for opportunity access.</p>
                    </div>
                </div>

                <!-- Project 2 -->
                <div class="project-card" id="project-2">
                    <h3>2. Fast Track Food Pickup Digital Service (MSc Dissertation)</h3>
                    <div class="project-meta">
                        <span><strong>Context:</strong> University of Roehampton, Distinction</span>
                        <span><strong>Domains:</strong> Digital Queuing, Perceived Fairness, Service Transparency, Sociotechnical Systems</span>
                    </div>
                    <p><strong>Methods:</strong> Mixed methods, interviews, surveys, thematic analysis, service blueprinting, UX evaluation</p>

                    <div class="project-section">
                        <h4>Overview</h4>
                        <p>This research examined how digital interfaces influence perceptions of fairness, time, and service credibility. The project involved designing a digital Fast-Track pickup experience for a food service environment where bottlenecks and unclear feedback loops lowered overall user satisfaction.</p>
                    </div>

                    <div class="project-section">
                        <h4>Research Problem</h4>
                        <p>Across many digital ordering systems, the biggest complaints relate not to actual time but perceived wait time. This perception is shaped by:</p>
                        <ul>
                            <li>transparency</li>
                            <li>environmental cues</li>
                            <li>interface feedback</li>
                            <li>trust in digital-to-physical handoff</li>
                        </ul>
                        <p>My research explored how perceived time, fairness, and trust are sociotechnically constructed.</p>
                    </div>

                    <div class="project-section">
                        <h4>What I Did</h4>
                        <p><strong>1. Collected Mixed-Method Data</strong></p>
                        <ul>
                            <li>Surveys captured quantitative satisfaction indicators</li>
                            <li>Interviews revealed qualitative expectations and psychological factors</li>
                            <li>Observational workflow mapping contextualized digital behaviors within physical service realities</li>
                        </ul>

                        <p><strong>2. Evaluated Interface Trust Cues</strong></p>
                        <p>Findings showed that:</p>
                        <ul>
                            <li>Time visibility improved perceived fairness</li>
                            <li>Users interpreted ambiguous cues as incompetence</li>
                            <li>Clear sequencing (order confirmed → preparing → ready) improved confidence</li>
                            <li>A lack of queue transparency led to distrust even when service was fast</li>
                        </ul>

                        <p><strong>3. Designed a Redesigned Service Blueprint</strong></p>
                        <p>The new blueprint provided:</p>
                        <ul>
                            <li>prediction-based wait estimates</li>
                            <li>transparent service states</li>
                            <li>consistent feedback signage</li>
                            <li>UX patterns inspired by reliability and clarity principles</li>
                        </ul>
                        <p><strong>Projected impact: ~35 percent improvement in perceived wait time.</strong></p>
                    </div>

                    <div class="project-section">
                        <h4>Scholarly Contribution</h4>
                        <p>This project deepened my interest in: sociotechnical fairness, digital representation of physical systems, psychological construction of time and waiting, and trust as a hybrid of interface cues and environmental signals. It served as my entry point into HCI research.</p>
                    </div>
                </div>

                <!-- Project 3 -->
                <div class="project-card" id="project-3">
                    <h3>3. AI Accessibility Feature for Sky (Professional Certificate Capstone)</h3>
                    <div class="project-meta">
                        <span><strong>Context:</strong> King's College London</span>
                        <span><strong>Domains:</strong> Accessibility, AI Personalization, Inclusive Media Design, Regulation (WCAG, Ofcom)</span>
                    </div>
                    <p><strong>Methods:</strong> Accessibility heuristics, user story mapping, collaborative prototyping, regulatory analysis</p>

                    <div class="project-section">
                        <h4>Overview</h4>
                        <p>In collaboration with Sky, I worked on designing an AI-powered media accessibility feature that adapted content presentation based on user needs while respecting regulatory frameworks.</p>
                    </div>

                    <div class="project-section">
                        <h4>What I Did</h4>
                        <p><strong>1. Mapped Accessibility Needs</strong></p>
                        <p>Analyzed needs of users with:</p>
                        <ul>
                            <li>sensory sensitivities</li>
                            <li>cognitive differences</li>
                            <li>reading/comprehension challenges</li>
                        </ul>

                        <p><strong>2. Developed Inclusive User Stories</strong></p>
                        <p>Stories emphasized:</p>
                        <ul>
                            <li>control</li>
                            <li>comprehension</li>
                            <li>comfort</li>
                            <li>transparency and consent</li>
                            <li>ability to override automated adjustments</li>
                        </ul>

                        <p><strong>3. Balanced Personalization With User Autonomy</strong></p>
                        <p>The key tension was: <em>Can AI personalize without becoming intrusive or paternalistic?</em></p>
                        <p>I approached this by:</p>
                        <ul>
                            <li>foregrounding user-set preferences</li>
                            <li>limiting unsolicited adjustments</li>
                            <li>ensuring explanations of automated behaviors</li>
                            <li>enabling predictable interaction patterns</li>
                        </ul>
                    </div>

                    <div class="project-section">
                        <h4>Impact & Research Value</h4>
                        <p>This project revealed how accessibility, personalization, and value-sensitive design intersect. It strengthened my interest in: cross-cultural accessibility, adaptive AI for diverse cognitive styles, and ethical personalization frameworks.</p>
                    </div>
                </div>

                <!-- Project 4 -->
                <div class="project-card" id="project-4">
                    <h3>4. CSR Data Annotation & Ethical Dataset Construction (Isahit)</h3>
                    <div class="project-meta">
                        <span><strong>Context:</strong> Paris-based AI dataset platform</span>
                        <span><strong>Domains:</strong> Dataset documentation, ambiguity resolution, bias detection, CSR thematic analysis</span>
                    </div>
                    <p><strong>Methods:</strong> Annotation studies, content categorization, reliability checks</p>

                    <div class="project-section">
                        <h4>Overview</h4>
                        <p>This work gave me hands-on experience with dataset ambiguity, annotation inconsistency, and the human labor behind AI data pipelines. I contributed to categorizing CSR-related content for training AI models and saw how labeling decisions propagate into model behavior.</p>
                        <p>It reinforced my commitment to interpretability and highlighted the ethical responsibility embedded in data preprocessing.</p>
                    </div>
                </div>

                <!-- Project 5 -->
                <div class="project-card" id="project-5">
                    <h3>5. Digital Equity & Development Research (Dataville)</h3>
                    <div class="project-meta">
                        <span><strong>Domains:</strong> ICT4D, AI for Social Good, Development Studies</span>
                    </div>
                    <p><strong>Methods:</strong> Mixed methods, policy review, contextual analysis</p>

                    <div class="project-section">
                        <h4>Overview</h4>
                        <p>Explored how technology, policy, and sociotechnical context shape global inequities. This broadened my understanding of the systemic forces that influence AI access and fairness.</p>
                    </div>
                </div>

                <!-- Project 6 -->
                <div class="project-card" id="project-6">
                    <h3>6. Data, Insight & Behavioral Analysis Work</h3>

                    <div class="project-section">
                        <h4>Overview</h4>
                        <p>Across multiple roles, I conducted:</p>
                        <ul>
                            <li>SQL/Python behavioral analysis</li>
                            <li>interaction pattern mining</li>
                            <li>service usage segmentation</li>
                            <li>simple predictive modeling to understand risk/uncertainty clusters</li>
                            <li>dashboard design for non-technical stakeholders</li>
                        </ul>
                        <p>These experiences strengthened my analytical lens and helped me frame AI design questions in empirical terms.</p>
                    </div>
                </div>

                <div class="contact-info" id="collaboration">
                    <h3>Interested in collaborating?</h3>
                    <p>
                        <a href="mailto:ubongenonkereuwem@gmail.com">ubongenonkereuwem@gmail.com</a>
                        <br>
                        <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noopener noreferrer">LinkedIn: linkedin.com/in/ubongeno</a>
                    </p>
                </div>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 Ubong Eno Nkereuwem. All rights reserved.</p>
            <p>
                <a href="mailto:ubongenonkereuwem@gmail.com">Email</a> · 
                <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noopener noreferrer">LinkedIn</a>
            </p>
        </div>
    </footer>
</body>
</html>
