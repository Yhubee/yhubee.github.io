<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Projects and Case Studies by Ubong Eno Nkereuwem - AI + HCI work across EdTech, accessibility, and sociotechnical contexts.">
    <meta name="author" content="Ubong Eno Nkereuwem">
    <title>Projects & Case Studies | Ubong Eno Nkereuwem</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <a href="index.html" class="logo">Ubong Eno Nkereuwem</a>
            <nav>
                <a href="index.html">Home</a>
                <a href="about.html">About</a>
                <a href="projects.html" class="active">Projects</a>
                <a href="research.html">Research</a>
                <a href="teaching.html">Teaching</a>
                <a href="why.html">Why This Work</a>
            </nav>
        </div>
    </header>

    <div class="page-header">
        <div class="container">
            <h1>Projects</h1>
            <p class="lead">Case studies in EdTech, accessibility, and sociotechnical design</p>
        </div>
    </div>

    <main>
        <div class="container">
            <div class="content-wrapper">

                <!-- Project 1 -->
                <div class="project-card">
                    <h3>Human–AI Learning Companion</h3>
                    <div class="project-meta">
                        <span>Technical AI PM & Researcher</span>
                        <span>Decision Support</span>
                        <span>Trust Calibration</span>
                    </div>

                    <p>International students face complex educational decisions—program selection, visa processes, career pathways—while navigating unfamiliar systems. My work examined how intelligent guidance can support clarity without inducing over-reliance.</p>

                    <div class="project-section">
                        <h4>The Problem</h4>
                        <p>Most advising systems present recommendations without transparency. Students often accept advice unquestioningly due to cognitive load or perceived authority. The risk: erosion of agency when recommendations subtly nudge students toward predefined pathways.</p>
                    </div>

                    <div class="project-section">
                        <h4>What I Did</h4>
                        <ul>
                            <li>Conducted interviews mapping uncertainty points and mental models of AI guidance</li>
                            <li>Co-developed adaptive explanation schemas based on risk level and user uncertainty</li>
                            <li>Implemented autonomy-preserving features: value-sensitive defaults, rationale prompts, reflection invitations</li>
                        </ul>
                    </div>

                    <div class="project-section">
                        <h4>Outcomes</h4>
                        <p>Increased engagement with advising content. Reduced blind acceptance of recommendations. Early evidence of trust calibration—users began questioning recommendations more thoughtfully.</p>
                    </div>
                </div>

                <!-- Project 2 -->
                <div class="project-card">
                    <h3>Fast Track Food Pickup Service</h3>
                    <div class="project-meta">
                        <span>MSc Dissertation</span>
                        <span>Distinction</span>
                        <span>Sociotechnical Systems</span>
                    </div>

                    <p>This research examined how digital interfaces influence perceptions of fairness, time, and service credibility—focusing on the gap between actual and perceived wait time.</p>

                    <div class="project-section">
                        <h4>Key Findings</h4>
                        <ul>
                            <li>Time visibility improved perceived fairness</li>
                            <li>Users interpreted ambiguous cues as incompetence</li>
                            <li>Clear sequencing (order confirmed → preparing → ready) improved confidence</li>
                            <li>Lack of queue transparency led to distrust even when service was fast</li>
                        </ul>
                    </div>

                    <div class="project-section">
                        <h4>Outcome</h4>
                        <p>Redesigned service blueprint projected to achieve ~35% improvement in perceived wait time. Entry point into HCI research.</p>
                    </div>
                </div>

                <!-- Project 3 -->
                <div class="project-card">
                    <h3>AI Accessibility Feature for Sky</h3>
                    <div class="project-meta">
                        <span>King's College London</span>
                        <span>WCAG/Ofcom</span>
                        <span>Inclusive Design</span>
                    </div>

                    <p>Designed an AI-powered media accessibility feature that adapts content presentation based on user needs while respecting regulatory frameworks.</p>

                    <div class="project-section">
                        <h4>Approach</h4>
                        <p>The key tension: Can AI personalize without becoming intrusive or paternalistic?</p>
                        <ul>
                            <li>Foregrounded user-set preferences</li>
                            <li>Limited unsolicited adjustments</li>
                            <li>Ensured explanations of automated behaviors</li>
                            <li>Enabled predictable interaction patterns</li>
                        </ul>
                    </div>
                </div>

                <!-- Project 4 -->
                <div class="project-card">
                    <h3>CSR Data Annotation</h3>
                    <div class="project-meta">
                        <span>Isahit (Paris)</span>
                        <span>Dataset Ethics</span>
                    </div>

                    <p>Hands-on experience with dataset ambiguity, annotation inconsistency, and the human labor behind AI data pipelines. Contributed to categorizing CSR content for AI training and saw how labeling decisions propagate into model behavior.</p>
                    
                    <p>Reinforced my commitment to interpretability and the ethical responsibility embedded in data preprocessing.</p>
                </div>

                <!-- Project 5 -->
                <div class="project-card">
                    <h3>Digital Equity Research</h3>
                    <div class="project-meta">
                        <span>Dataville</span>
                        <span>ICT4D</span>
                        <span>AI for Social Good</span>
                    </div>

                    <p>Explored how technology, policy, and sociotechnical context shape global inequities. Broadened my understanding of systemic forces that influence AI access and fairness.</p>
                </div>

                <div class="contact-info">
                    <h3>Interested in collaborating?</h3>
                    <p>
                        <a href="mailto:ubongenonkereuwem@gmail.com">ubongenonkereuwem@gmail.com</a>
                        <br><br>
                        <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noopener noreferrer">LinkedIn →</a>
                    </p>
                </div>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 Ubong Eno Nkereuwem</p>
            <p>
                <a href="mailto:ubongenonkereuwem@gmail.com">Email</a> · 
                <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noopener noreferrer">LinkedIn</a>
            </p>
        </div>
    </footer>
</body>
</html>
