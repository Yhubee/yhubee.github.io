<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Projects and Case Studies by Ubong Eno Nkereuwem - AI + HCI work across EdTech, accessibility, and sociotechnical contexts.">
    <meta name="author" content="Ubong Eno Nkereuwem">
    <title>Projects & Case Studies | Ubong Eno Nkereuwem</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <a class="skip-link" href="#main-content">Skip to content</a>
    <header>
        <div class="container">
            <a href="index.html" class="logo">Ubong Eno Nkereuwem</a>
            <nav role="navigation" aria-label="Primary">
                <a href="index.html">Home</a>
                <a href="about.html">About</a>
                <a href="projects.html" class="active" aria-current="page">Projects</a>
                <a href="research.html">Research</a>
                <a href="teaching.html">Teaching</a>
                <a href="why.html">Why This Work</a>
            </nav>
        </div>
    </header>

    <div class="page-header">
        <div class="container">
            <h1>Projects & Case Studies</h1>
            <p class="lead">A deep dive into my AI + HCI work across EdTech, accessibility, and sociotechnical contexts</p>
        </div>
    </div>

    <main id="main-content">
        <div class="container">
            <div class="content-wrapper">
                <p>My project work reflects a consistent thread: I use mixed-methods inquiry, sociotechnical reasoning, and ethical design practices to understand how intelligent systems influence, support, and sometimes interfere with human autonomy and decision-making. These case studies represent a blend of research, design, and computational awareness across EdTech, accessibility, and digital services.</p>

                <section aria-label="Projects overview">
                    <h2>AI + Learning &amp; Accessibility</h2>
                    <div class="projects-list">
                        <div class="project-item">
                            <a class="project-link" href="#project-1-detail">
                                <img class="project-thumb" src="content/assets/project-learning-companion.svg" alt="Illustration of an AI-powered advising companion interface">
                                <div class="project-copy">
                                    <h3>Human–AI Learning Companion for International Students</h3>
                                    <p>Designed an advising companion that pairs adaptive explanations with user-managed controls to help students navigate complex decisions without over-relying on AI guidance.</p>
                                    <span class="project-cta">Read the full case study</span>
                                </div>
                            </a>
                        </div>

                        <div class="project-item">
                            <a class="project-link" href="#project-3-detail">
                                <img class="project-thumb" src="content/assets/project-sky-accessibility.svg" alt="Abstract remote and screen showing personalized media controls">
                                <div class="project-copy">
                                    <h3>AI Accessibility Feature for Sky</h3>
                                    <p>Prototyped personalized media controls that respect user consent and accessibility regulations while keeping automated adjustments transparent.</p>
                                    <span class="project-cta">Read the full case study</span>
                                </div>
                            </a>
                        </div>
                    </div>

                    <h2>Service Design &amp; Data Ethics</h2>
                    <div class="projects-list">
                        <div class="project-item">
                            <a class="project-link" href="#project-2-detail">
                                <img class="project-thumb" src="content/assets/project-fast-track.svg" alt="Stylized dashboard for a fast-track pickup service">
                                <div class="project-copy">
                                    <h3>Fast Track Food Pickup Digital Service</h3>
                                    <p>Built and evaluated a transparent queueing experience that improves perceived fairness and trust in digital-to-physical service handoffs.</p>
                                    <span class="project-cta">Read the full case study</span>
                                </div>
                            </a>
                        </div>

                        <div class="project-item">
                            <a class="project-link" href="#project-4-detail">
                                <img class="project-thumb" src="content/assets/project-csr-annotation.svg" alt="Annotated documents representing CSR dataset labeling">
                                <div class="project-copy">
                                    <h3>CSR Data Annotation &amp; Ethical Dataset Construction</h3>
                                    <p>Examined how labeling ambiguity, reliability checks, and documentation practices shape responsible training data for AI systems.</p>
                                    <span class="project-cta">Read more about the annotation work</span>
                                </div>
                            </a>
                        </div>

                        <div class="project-item">
                            <a class="project-link" href="#project-5-detail">
                                <img class="project-thumb" src="content/assets/project-digital-equity.svg" alt="Globe illustration showing connected regions">
                                <div class="project-copy">
                                    <h3>Digital Equity &amp; Development Research</h3>
                                    <p>Researched how technology policy and sociotechnical contexts influence AI access and fairness within global development settings.</p>
                                    <span class="project-cta">View the research summary</span>
                                </div>
                            </a>
                        </div>

                        <div class="project-item">
                            <a class="project-link" href="#project-6-detail">
                                <img class="project-thumb" src="content/assets/project-data-insights.svg" alt="Analytics lines and bars representing dashboards">
                                <div class="project-copy">
                                    <h3>Data, Insight &amp; Behavioral Analysis Work</h3>
                                    <p>Delivered analytics and lightweight predictive modeling to uncover usage patterns, risk clusters, and dashboard insights for stakeholders.</p>
                                    <span class="project-cta">View the detailed overview</span>
                                </div>
                            </a>
                        </div>
                    </div>
                </section>

                <hr>

                <section class="project-details" aria-label="Project case studies">
                    <h2>Full case studies</h2>
                    <p>Expand the entries below to read the original, in-depth descriptions for each project.</p>

                    <details class="project-detail" id="project-1-detail">
                        <summary>Human–AI Learning Companion for International Students</summary>
                        <div class="project-meta">
                            <span><strong>Role:</strong> Technical AI Product Manager &amp; Human–Centered AI Researcher</span>
                            <span><strong>Domains:</strong> Decision Support, Explanation Design, Trust Calibration, Digital Learning Ecosystems</span>
                        </div>
                        <p><strong>Methods:</strong> Semi-structured interviews, cognitive mapping, interaction prototyping, behavioral analysis, explainability modeling</p>
                        <p>This learning companion explores how intelligent advising can clarify choices without overriding learner agency. It experiments with adaptive explanations, visible system limitations, and user-managed controls to counter confidence bias.</p>

                        <div class="project-section">
                            <h4>Overview</h4>
                            <p>International students face complex educational decisions—program selection, visa processes, academic expectations, and career pathways—all while navigating unfamiliar cultural and institutional systems. These decisions involve uncertainty, high stakes, and emotional burden. My work on the AI Learning Companion examined how intelligent guidance systems can support clarity and confidence without inducing over-reliance.</p>
                        </div>

                        <div class="project-section">
                            <h4>Problem Framing</h4>
                            <p>Most digital advising systems present recommendations without transparency. Students experiencing stress or limited familiarity with local academic structures often accept advice unquestioningly. The risk is twofold:</p>
                            <ol>
                                <li>Over-reliance due to cognitive load, perceived authority, or system confidence</li>
                                <li>Erosion of agency when recommendations subtly nudge students toward predefined pathways</li>
                            </ol>
                            <p>My goal was to design an AI system that supports, not supplants, human judgment.</p>
                        </div>

                        <div class="project-section">
                            <h4>What I Did</h4>
                            <p><strong>1. Researching Real Help-Seeking Behaviors</strong></p>
                            <p>I conducted interviews with international students to map:</p>
                            <ul>
                                <li>uncertainty points</li>
                                <li>mental models of institutional processes</li>
                                <li>expectations of AI guidance</li>
                                <li>perceived emotional/life stakes of decisions</li>
                            </ul>
                            <p>Students frequently interpreted AI confidence as correctness, especially when overwhelmed. This echoed patterns I observed in other settings—such as Maria, an autistic user who gradually deferred to an AI system's recommendations because it appeared "sure"—highlighting the universality of confidence bias in AI-mediated decision making.</p>

                            <p><strong>2. Designing Adaptive Explanation Patterns</strong></p>
                            <p>I co-developed an explanation schema that adjusted based on:</p>
                            <ul>
                                <li>question type</li>
                                <li>risk level</li>
                                <li>user uncertainty signals</li>
                                <li>amount of context the user provided</li>
                                <li>whether the user asked for justification or alternatives</li>
                            </ul>
                            <p>Examples included: "reasoned recommendations," "confidence-qualified suggestions," "multiple-pathway explanations," and "limited knowledge disclosures." These aimed to support healthy skepticism and informed choice.</p>

                            <p><strong>3. Introducing Autonomy-Preserving Interaction Boundaries</strong></p>
                            <p>I implemented features such as:</p>
                            <ul>
                                <li>user-managed control settings</li>
                                <li>value-sensitive defaults</li>
                                <li>rationale prompts</li>
                                <li>calls to double-check institutional requirements</li>
                                <li>invitation to reflect ("Does this align with what you want?")</li>
                            </ul>
                            <p>These were grounded in principles of FATE, sensemaking, and human–AI complementarity.</p>
                        </div>

                        <div class="project-section">
                            <h4>Outcomes</h4>
                            <ul>
                                <li>Increased student engagement with learning and advising content</li>
                                <li>Greater user awareness of system limitations</li>
                                <li>Reduced blind acceptance of system recommendations</li>
                                <li>Early evidence of trust calibration (users began questioning recommendations more thoughtfully)</li>
                                <li>Identification of behavioral clusters that now inform adaptive UI/UX flows</li>
                            </ul>
                        </div>

                        <div class="project-section">
                            <h4>Scholarly Contribution</h4>
                            <p>This project helped refine my research agenda on: trust drift over repeated human–AI interactions, explanation strategies tailored to user cognition, longitudinal measurement of autonomy and self-efficacy, and sociotechnical design for opportunity access.</p>
                        </div>
                    </details>

                    <details class="project-detail" id="project-2-detail">
                        <summary>Fast Track Food Pickup Digital Service (MSc Dissertation)</summary>
                        <div class="project-meta">
                            <span><strong>Context:</strong> University of Roehampton, Distinction</span>
                            <span><strong>Domains:</strong> Digital Queuing, Perceived Fairness, Service Transparency, Sociotechnical Systems</span>
                        </div>
                        <p><strong>Methods:</strong> Mixed methods, interviews, surveys, thematic analysis, service blueprinting, UX evaluation</p>

                        <p>This dissertation focused on the sociotechnical factors shaping perceived fairness and waiting time in semi-automated food pickup experiences.</p>

                        <div class="project-section">
                            <h4>Overview</h4>
                            <p>This research examined how digital interfaces influence perceptions of fairness, time, and service credibility. The project involved designing a digital Fast-Track pickup experience for a food service environment where bottlenecks and unclear feedback loops lowered overall user satisfaction.</p>
                        </div>

                        <div class="project-section">
                            <h4>Research Problem</h4>
                            <p>Across many digital ordering systems, the biggest complaints relate not to actual time but perceived wait time. This perception is shaped by:</p>
                            <ul>
                                <li>transparency</li>
                                <li>environmental cues</li>
                                <li>interface feedback</li>
                                <li>trust in digital-to-physical handoff</li>
                            </ul>
                            <p>My research explored how perceived time, fairness, and trust are sociotechnically constructed.</p>
                        </div>

                        <div class="project-section">
                            <h4>What I Did</h4>
                            <p><strong>1. Collected Mixed-Method Data</strong></p>
                            <ul>
                                <li>Surveys captured quantitative satisfaction indicators</li>
                                <li>Interviews revealed qualitative expectations and psychological factors</li>
                                <li>Observational workflow mapping contextualized digital behaviors within physical service realities</li>
                            </ul>

                            <p><strong>2. Evaluated Interface Trust Cues</strong></p>
                            <p>Findings showed that:</p>
                            <ul>
                                <li>Time visibility improved perceived fairness</li>
                                <li>Users interpreted ambiguous cues as incompetence</li>
                                <li>Clear sequencing (order confirmed → preparing → ready) improved confidence</li>
                                <li>A lack of queue transparency led to distrust even when service was fast</li>
                            </ul>

                            <p><strong>3. Designed a Redesigned Service Blueprint</strong></p>
                            <p>The new blueprint provided:</p>
                            <ul>
                                <li>prediction-based wait estimates</li>
                                <li>transparent service states</li>
                                <li>consistent feedback signage</li>
                                <li>UX patterns inspired by reliability and clarity principles</li>
                            </ul>
                            <p><strong>Projected impact: ~35 percent improvement in perceived wait time.</strong></p>
                        </div>

                        <div class="project-section">
                            <h4>Scholarly Contribution</h4>
                            <p>This project deepened my interest in: sociotechnical fairness, digital representation of physical systems, psychological construction of time and waiting, and trust as a hybrid of interface cues and environmental signals. It served as my entry point into HCI research.</p>
                        </div>
                    </details>

                    <details class="project-detail" id="project-3-detail">
                        <summary>AI Accessibility Feature for Sky (Professional Certificate Capstone)</summary>
                        <div class="project-meta">
                            <span><strong>Context:</strong> King's College London</span>
                            <span><strong>Domains:</strong> Accessibility, AI Personalization, Inclusive Media Design, Regulation (WCAG, Ofcom)</span>
                        </div>
                        <p><strong>Methods:</strong> Accessibility heuristics, user story mapping, collaborative prototyping, regulatory analysis</p>

                        <p>This capstone examined how AI-driven accessibility controls can personalize media experiences while keeping users in control of automated adjustments.</p>

                        <div class="project-section">
                            <h4>Overview</h4>
                            <p>In collaboration with Sky, I worked on designing an AI-powered media accessibility feature that adapted content presentation based on user needs while respecting regulatory frameworks.</p>
                        </div>

                        <div class="project-section">
                            <h4>What I Did</h4>
                            <p><strong>1. Mapped Accessibility Needs</strong></p>
                            <p>Analyzed needs of users with:</p>
                            <ul>
                                <li>sensory sensitivities</li>
                                <li>cognitive differences</li>
                                <li>reading/comprehension challenges</li>
                            </ul>

                            <p><strong>2. Developed Inclusive User Stories</strong></p>
                            <p>Stories emphasized:</p>
                            <ul>
                                <li>control</li>
                                <li>comprehension</li>
                                <li>comfort</li>
                                <li>transparency and consent</li>
                                <li>ability to override automated adjustments</li>
                            </ul>

                            <p><strong>3. Balanced Personalization With User Autonomy</strong></p>
                            <p>The key tension was: <em>Can AI personalize without becoming intrusive or paternalistic?</em></p>
                            <p>I approached this by:</p>
                            <ul>
                                <li>foregrounding user-set preferences</li>
                                <li>limiting unsolicited adjustments</li>
                                <li>ensuring explanations of automated behaviors</li>
                                <li>enabling predictable interaction patterns</li>
                            </ul>
                        </div>

                        <div class="project-section">
                            <h4>Impact &amp; Research Value</h4>
                            <p>This project revealed how accessibility, personalization, and value-sensitive design intersect. It strengthened my interest in: cross-cultural accessibility, adaptive AI for diverse cognitive styles, and ethical personalization frameworks.</p>
                        </div>
                    </details>

                    <details class="project-detail" id="project-4-detail">
                        <summary>CSR Data Annotation &amp; Ethical Dataset Construction (Isahit)</summary>
                        <div class="project-meta">
                            <span><strong>Context:</strong> Paris-based AI dataset platform</span>
                            <span><strong>Domains:</strong> Dataset documentation, ambiguity resolution, bias detection, CSR thematic analysis</span>
                        </div>
                        <p><strong>Methods:</strong> Annotation studies, content categorization, reliability checks</p>

                        <p>Annotated CSR datasets to understand how labeling ambiguity and human decision-making shape downstream model behavior.</p>

                        <div class="project-section">
                            <h4>Overview</h4>
                            <p>This work gave me hands-on experience with dataset ambiguity, annotation inconsistency, and the human labor behind AI data pipelines. I contributed to categorizing CSR-related content for training AI models and saw how labeling decisions propagate into model behavior.</p>
                            <p>It reinforced my commitment to interpretability and highlighted the ethical responsibility embedded in data preprocessing.</p>
                        </div>
                    </details>

                    <details class="project-detail" id="project-5-detail">
                        <summary>Digital Equity &amp; Development Research (Dataville)</summary>
                        <div class="project-meta">
                            <span><strong>Domains:</strong> ICT4D, AI for Social Good, Development Studies</span>
                        </div>
                        <p><strong>Methods:</strong> Mixed methods, policy review, contextual analysis</p>

                        <div class="project-section">
                            <h4>Overview</h4>
                            <p>Explored how technology, policy, and sociotechnical context shape global inequities. This broadened my understanding of the systemic forces that influence AI access and fairness.</p>
                        </div>
                    </details>

                    <details class="project-detail" id="project-6-detail">
                        <summary>Data, Insight &amp; Behavioral Analysis Work</summary>
                        <div class="project-section">
                            <h4>Overview</h4>
                            <p>Across multiple roles, I conducted:</p>
                            <ul>
                                <li>SQL/Python behavioral analysis</li>
                                <li>interaction pattern mining</li>
                                <li>service usage segmentation</li>
                                <li>simple predictive modeling to understand risk/uncertainty clusters</li>
                                <li>dashboard design for non-technical stakeholders</li>
                            </ul>
                            <p>These experiences strengthened my analytical lens and helped me frame AI design questions in empirical terms.</p>
                        </div>
                    </details>
                </section>

            </div>
        </div>
    </main>

    <div data-include="footer.html"></div>
    <script src="scripts.js"></script>
</body>
</html>
