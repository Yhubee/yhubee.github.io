<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Research and Writing by Ubong Eno Nkereuwem - Human-AI interaction, trust calibration, and sociotechnical systems research.">
    <meta name="author" content="Ubong Eno Nkereuwem">
    <title>Research | Ubong Eno Nkereuwem</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <a href="index.html" class="logo">Ubong Eno Nkereuwem</a>
            <nav>
                <a href="index.html">Home</a>
                <a href="about.html">About</a>
                <a href="projects.html">Projects</a>
                <a href="research.html" class="active">Research</a>
                <a href="teaching.html">Teaching</a>
                <a href="why.html">Why This Work</a>
            </nav>
        </div>
    </header>

    <div class="page-header">
        <div class="container">
            <h1>Research</h1>
            <p class="lead">How people interpret, trust, and collaborate with intelligent systems</p>
        </div>
    </div>

    <main>
        <div class="container">
            <div class="content-wrapper">
                <p class="lead-text">I study how sociotechnical design influences autonomy, judgment, and value alignment over time—particularly in contexts involving uncertainty, emotional stakes, and information asymmetry.</p>

                <hr>

                <h2>Research Themes</h2>

                <div class="theme-card">
                    <h3>Mental Model Formation</h3>
                    <p>How users form and update mental models of AI systems. I study how confidence signals, explanation style, and environmental uncertainty shape what users believe about system competence and limitations.</p>
                </div>

                <div class="theme-card">
                    <h3>Trust Calibration</h3>
                    <p>Building interfaces that encourage calibrated trust—the alignment of user confidence with actual system competence. I study trust drift, behavioral signals of over/under-reliance, and design patterns that strengthen user control.</p>
                </div>

                <div class="theme-card">
                    <h3>Adaptive Explanation Design</h3>
                    <p>Not all users benefit from the same explanation style. I investigate cognitively adaptive explanations, culturally aware framing, and when to offer multi-pathway reasoning.</p>
                </div>

                <div class="theme-card">
                    <h3>Sociotechnical Fairness</h3>
                    <p>How AI nudges shape opportunity access, how predictive systems influence choice architecture, and how algorithmic recommendations intersect with cultural and structural inequities.</p>
                </div>

                <hr>

                <h2>Emerging Directions</h2>

                <div class="interests-grid">
                    <div class="interest-card">
                        <h4>Autonomy Drift</h4>
                        <p>How repeated AI interactions influence confidence, agency, and self-efficacy.</p>
                    </div>
                    <div class="interest-card">
                        <h4>Explanation Timing</h4>
                        <p>Which structures reduce blind reliance while supporting clarity.</p>
                    </div>
                    <div class="interest-card">
                        <h4>Dynamic Value Alignment</h4>
                        <p>How AI can adapt as user needs and goals change.</p>
                    </div>
                    <div class="interest-card">
                        <h4>Longitudinal Evaluation</h4>
                        <p>Measuring autonomy and trust calibration over time.</p>
                    </div>
                </div>

                <hr>

                <h2>Methods</h2>

                <div class="interests-grid">
                    <div class="interest-card">
                        <h4>Qualitative</h4>
                        <p>Semi-structured interviews, thematic coding, usability testing, contextual inquiry, journey mapping</p>
                    </div>
                    <div class="interest-card">
                        <h4>Quantitative</h4>
                        <p>Survey design, behavioral analysis, A/B studies, psychometric considerations</p>
                    </div>
                    <div class="interest-card">
                        <h4>Design</h4>
                        <p>Value-sensitive design, ethical UX, trust calibration frameworks, service blueprinting</p>
                    </div>
                    <div class="interest-card">
                        <h4>Technical</h4>
                        <p>Python, SQL, interface prototyping, annotation analysis</p>
                    </div>
                </div>

                <hr>

                <h2>Guiding Questions</h2>
                <ul>
                    <li>How do humans decide when to trust or question an intelligent system?</li>
                    <li>How do mental models of AI evolve over repeated interactions?</li>
                    <li>What design cues prevent over-reliance without overwhelming users?</li>
                    <li>How does AI influence opportunity access for learners navigating opaque systems?</li>
                </ul>

                <div class="summary-box">
                    <h3>Long-Term Vision</h3>
                    <p>To establish a Human–Centered AI Research Lab focused on adaptive trust frameworks, EdTech fairness, AI accessibility, and ethical algorithmic governance—bridging academia, industry, and policy.</p>
                </div>

                <div class="contact-info">
                    <h3>Let's Connect</h3>
                    <p>
                        <a href="mailto:ubongenonkereuwem@gmail.com">ubongenonkereuwem@gmail.com</a>
                        <br><br>
                        <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noopener noreferrer">LinkedIn →</a>
                    </p>
                </div>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 Ubong Eno Nkereuwem</p>
            <p>
                <a href="mailto:ubongenonkereuwem@gmail.com">Email</a> · 
                <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noopener noreferrer">LinkedIn</a>
            </p>
        </div>
    </footer>
</body>
</html>
