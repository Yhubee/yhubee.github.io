<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Case study: CSR Data Annotation and ethical dataset construction by Ubong Eno Nkereuwem.">
    <meta name="author" content="Ubong Eno Nkereuwem">
    <title>CSR Data Annotation & Ethical Dataset Construction | Ubong Eno Nkereuwem</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <a class="skip-link" href="#main-content">Skip to content</a>
    <header>
        <div class="container">
            <a href="index.html" class="logo">Ubong Eno Nkereuwem</a>
            <nav role="navigation" aria-label="Primary">
                <a href="index.html">Home</a>
                <a href="about.html">About</a>
                <a href="projects.html" class="active" aria-current="page">Projects</a>
                <a href="research.html">Research</a>
                <a href="teaching.html">Teaching</a>
                <a href="why.html">Why This Work</a>
                <a href="index.html#contact">Contact</a>
            </nav>
        </div>
    </header>

    <div class="page-header">
        <div class="container">
            <h1>CSR Data Annotation &amp; Ethical Dataset Construction</h1>
            <p class="lead">Examining how labeling ambiguity and documentation practices shape responsible training data.</p>
        </div>
    </div>

    <main id="main-content">
        <div class="container">
            <div class="content-wrapper">
                <section class="project-hero">
                    <p class="project-role"><strong>Role:</strong> Annotator &amp; Data Ethics Researcher</p>
                    <p class="project-context"><strong>Context:</strong> Paris-based AI dataset platform</p>
                    <p class="project-domains"><strong>Domains:</strong> Dataset documentation, ambiguity resolution, bias detection, CSR thematic analysis</p>
                    <p class="project-methods"><strong>Methods:</strong> Annotation studies, content categorization, reliability checks</p>
                </section>

                <figure class="project-visual">
                    <img src="content/assets/project-csr-annotation.svg" alt="Diagram of inclusive data annotation workflow and impact">
                    <figcaption>Mapping how thoughtful prompts and documentation improve both dataset quality and worker wellbeing.</figcaption>
                </figure>

                <p class="back-to-projects">← <a href="projects.html">Back to Projects &amp; Case Studies</a></p>

                <section class="project-section">
                    <h2>Overview</h2>
                    <p>Annotating CSR datasets gave me hands-on experience with dataset ambiguity, annotation inconsistency, and the human labor behind AI data pipelines. I contributed to categorizing CSR-related content for training AI models and saw how labeling decisions propagate into model behavior.</p>
                    <p>The work reinforced my commitment to interpretability and highlighted the ethical responsibility embedded in data preprocessing and documentation.</p>
                </section>

                <section class="project-section">
                    <h2>Key Artifacts</h2>
                    <div class="artifact-grid">
                        <div class="card artifact-card">
                            <div class="artifact-icon" aria-hidden="true">GL</div>
                            <h4>Annotation guideline matrix (placeholder)</h4>
                            <ul>
                                <li>Documented examples of ambiguous CSR content</li>
                                <li>Outlined escalation paths for unclear labels</li>
                                <li>Linked label choices to potential model behaviors</li>
                            </ul>
                        </div>
                        <div class="card artifact-card">
                            <div class="artifact-icon" aria-hidden="true">QA</div>
                            <h4>Quality review board (placeholder)</h4>
                            <ul>
                                <li>Tracked inter-annotator agreement sessions</li>
                                <li>Captured rationales for merging or splitting labels</li>
                                <li>Flagged sources of bias from source material</li>
                            </ul>
                        </div>
                        <div class="card artifact-card">
                            <div class="artifact-icon" aria-hidden="true">DS</div>
                            <h4>Dataset documentation snippets (placeholder)</h4>
                            <ul>
                                <li>Summarized collection methods and topic balance</li>
                                <li>Recorded caveats about cultural framing in CSR narratives</li>
                                <li>Proposed maintenance steps for future annotation rounds</li>
                            </ul>
                        </div>
                    </div>
                    <div class="note-box">
                        <p>Small wording changes in the guideline matrix dramatically shifted labeling consistency—evidence that responsible AI starts with thoughtful annotation scaffolds.</p>
                    </div>
                </section>

                <p class="back-to-projects">← <a href="projects.html">Back to Projects &amp; Case Studies</a></p>
            </div>
        </div>
    </main>

    <div data-include="footer.html"></div>
    <script src="scripts.js"></script>
</body>
</html>
