<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Why I Do This Work | Ubong Eno Nkereuwem</title>
  <meta name="description" content="The motivations behind my Human–Centered AI research on autonomy, trust, and human dignity." />
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <div class="navbar">
      <div class="brand">Ubong Eno Nkereuwem</div>
      <nav aria-label="Primary">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="about.html">About</a></li>
          <li><a href="projects.html">Projects</a></li>
          <li><a href="research.html">Research</a></li>
          <li><a href="publications.html">Publications</a></li>
          <li><a href="teaching.html">Teaching</a></li>
          <li><a class="active" href="why.html">Why I Do This Work</a></li>
          <li><a href="bio.html">Bio</a></li>
        </ul>
      </nav>
    </div>
  </header>
  <main class="container">
    <h1>Why I Do This Work</h1>
    <p>My commitment to Human–Centered AI was shaped by moments where I saw how easily intelligent systems can influence human decision-making—sometimes quietly, subtly, and without users realizing it.</p>
    <p>One defining moment was a research session involving an autistic user, whom I refer to as Maria. She relied on predictable patterns to anchor herself when interacting with digital tools. Each time the AI-generated suggestion matched her expectations, she smiled with relief. But when the system deviated, she paused, unsure how to interpret the deviation. Over multiple interactions, I watched her gradually defer to the AI—not out of trust earned but out of cognitive fatigue and perceived system authority.</p>
    <p>It was a stunning realization: AI systems do not need to be dominant to displace human judgment; they only need to be confident in the presence of user uncertainty. This moment crystallized the purpose behind my work—to design and study AI systems that reinforce autonomy, preserve self-determination, and strengthen—not overshadow—human reasoning.</p>

    <div class="section-divider"></div>

    <section>
      <h2>The Deeper Problem I Want to Solve</h2>
      <p>Across my work in EdTech, I saw how opaque recommendations from AI systems can influence educational pathways, career trajectories, and personal identity. Students often accept AI-generated suggestions because they feel lost, overwhelmed, or intimidated by complex institutional processes. In these cases, AI becomes a silent decision-maker, users mistake confidence for correctness, and human agency is gradually displaced.</p>
      <p>I designed transparency mechanisms, adaptive explanations, and value-sensitive defaults—but realized that ethical UX is only the first step. What we lack in industry is rigorous, longitudinal measurement of autonomy, models for evaluating trust drift, methods for detecting over-reliance, and frameworks for supporting value alignment over time. My research aims to address this gap directly.</p>
    </section>

    <section>
      <h2>My Purpose as a Researcher</h2>
      <p>I pursue Human–Centered AI research because I want intelligent systems to participate in human life in ways that uphold dignity, agency, fairness, interpretability, emotional safety, and long-term autonomy. The communities I have taught and led—girls in Abuja, secondary school learners in Benin City, youth across Nigeria, vulnerable users in London—reinforce my belief that technology must adapt to the human being, not the other way around.</p>
      <p>My long-term goal is to help build theoretical frameworks, empirical methods, and design principles for AI systems that communicate uncertainty responsibly, adapt explanations to user cognition and cultural context, avoid nudging users into predetermined choices, preserve human decision authority, align with evolving human values, support learning rather than dependency, and respect cognitive differences and vulnerabilities. I want to contribute to a future where users like Maria can interact with AI that strengthens—rather than diminishes—their confidence in their own judgment.</p>
    </section>
  </main>
  <footer class="footer">
    <div class="container">
      <div class="small">© Ubong Eno Nkereuwem</div>
      <div class="small">Email: <a href="mailto:ubongenonkereuwem@gmail.com">ubongenonkereuwem@gmail.com</a> · <a href="https://www.linkedin.com/in/ubongeno" target="_blank" rel="noreferrer">LinkedIn</a></div>
    </div>
  </footer>
</body>
</html>
